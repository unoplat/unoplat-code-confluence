{
  "module_docstring": null,
  "global_variables": [
    {
      "start_line": 147,
      "end_line": 149,
      "signature": "logger = setup_logging(\n    service_name=\"code-confluence-flow-bridge\", app_name=\"unoplat-code-confluence\"\n)"
    },
    {
      "start_line": 573,
      "end_line": 573,
      "signature": "origins: List[str] = os.getenv(\"ALLOWED_ORIGINS\", \"http://localhost:5173\").split(\",\")"
    },
    {
      "start_line": 570,
      "end_line": 570,
      "signature": "app = FastAPI(lifespan=lifespan)"
    }
  ],
  "functions": [
    {
      "start_line": 155,
      "end_line": 163,
      "signature": "async def get_temporal_client() -> Client:",
      "docstring": "Create and return a Temporal client instance.",
      "function_calls": [
        "os.getenv(\"TEMPORAL_SERVER_ADDRESS\", \"localhost:7233\")",
        "Client.connect(\n        temporal_server, data_converter=pydantic_data_converter\n    )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 166,
      "end_line": 170,
      "signature": "async def _serve_worker(stop: asyncio.Event, worker: Worker) -> None:",
      "docstring": "Keep the worker running until `stop` is set, then shut it down.",
      "function_calls": [
        "stop.wait()"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 173,
      "end_line": 314,
      "signature": "def create_worker(\n    activities: List[Callable],\n    client: Client,\n    activity_executor: ThreadPoolExecutor,\n    env_settings: EnvironmentSettings,\n) -> Worker:",
      "docstring": "\n    Create a Temporal worker with given activities\n\n    Args:\n        activities: List of activity functions\n        client: Temporal client\n        activity_executor: Thread pool executor for activities\n        env_settings: Environment settings containing Temporal worker configuration\n\n    Returns:\n        Worker: Configured Temporal worker instance\n    ",
      "function_calls": [
        "ParentWorkflowStatusInterceptor()",
        "ActivityStatusInterceptor()",
        "PollerBehaviorAutoscaling(\n                minimum=env_settings.temporal_workflow_poller_min,\n                initial=env_settings.temporal_workflow_poller_initial,\n                maximum=env_settings.temporal_workflow_poller_max,\n            )",
        "PollerBehaviorAutoscaling(\n                minimum=env_settings.temporal_activity_poller_min,\n                initial=env_settings.temporal_activity_poller_initial,\n                maximum=env_settings.temporal_activity_poller_max,\n            )",
        "logger.info(\n                \"Starting Temporal worker with autoscaling pollers enabled. \"\n                \"Workflow poller: min={}, initial={}, max={}. \"\n                \"Activity poller: min={}, initial={}, max={}\",\n                env_settings.temporal_workflow_poller_min,\n                env_settings.temporal_workflow_poller_initial,\n                env_settings.temporal_workflow_poller_max,\n                env_settings.temporal_activity_poller_min,\n                env_settings.temporal_activity_poller_initial,\n                env_settings.temporal_activity_poller_max,\n            )",
        "logger.info(\n                \"\"\"Starting Temporal worker with max_concurrent_activities={},\n                max_concurrent_activity_task_polls={},\n                repository base path={}\"\"\",\n                env_settings.temporal_max_concurrent_activities,\n                env_settings.temporal_max_concurrent_activity_task_polls,\n                env_settings.repositories_base_path,\n            )",
        "Worker(\n                client,  # Client must be passed as a positional argument\n                task_queue=\"unoplat-code-confluence-repository-context-ingestion\",\n                workflows=[RepoWorkflow, CodebaseChildWorkflow],\n                activities=activities,\n                activity_executor=activity_executor,\n                interceptors=[\n                    ParentWorkflowStatusInterceptor(),\n                    ActivityStatusInterceptor(),\n                ],\n                max_concurrent_activities=env_settings.temporal_max_concurrent_activities,\n                # Configure poller behaviors with autoscaling\n                workflow_task_poller_behavior=PollerBehaviorAutoscaling(\n                    minimum=env_settings.temporal_workflow_poller_min,\n                    initial=env_settings.temporal_workflow_poller_initial,\n                    maximum=env_settings.temporal_workflow_poller_max,\n                ),\n                activity_task_poller_behavior=PollerBehaviorAutoscaling(\n                    minimum=env_settings.temporal_activity_poller_min,\n                    initial=env_settings.temporal_activity_poller_initial,\n                    maximum=env_settings.temporal_activity_poller_max,\n                ),\n            )",
        "ParentWorkflowStatusInterceptor()",
        "ActivityStatusInterceptor()",
        "PollerBehaviorAutoscaling(\n                    minimum=env_settings.temporal_workflow_poller_min,\n                    initial=env_settings.temporal_workflow_poller_initial,\n                    maximum=env_settings.temporal_workflow_poller_max,\n                )",
        "PollerBehaviorAutoscaling(\n                    minimum=env_settings.temporal_activity_poller_min,\n                    initial=env_settings.temporal_activity_poller_initial,\n                    maximum=env_settings.temporal_activity_poller_max,\n                )",
        "Worker(\n                client,  # Client must be passed as a positional argument\n                task_queue=\"unoplat-code-confluence-repository-context-ingestion\",\n                workflows=[RepoWorkflow, CodebaseChildWorkflow],\n                activities=activities,\n                activity_executor=activity_executor,\n                interceptors=[\n                    ParentWorkflowStatusInterceptor(),\n                    ActivityStatusInterceptor(),\n                ],\n                max_concurrent_activities=env_settings.temporal_max_concurrent_activities,\n                max_concurrent_activity_task_polls=env_settings.temporal_max_concurrent_activity_task_polls,\n            )",
        "ParentWorkflowStatusInterceptor()",
        "ActivityStatusInterceptor()",
        "str(e)",
        "traceback.format_exc()",
        "logger.error(\n            \"Failed to start Temporal worker: {}\",\n            str(e),\n            extra={\"error_context\": error_context},\n        )",
        "str(e)",
        "\"Failed to start Temporal worker: {}\".format(str(e))",
        "str(e)",
        "ApplicationError(error_message, type=\"WORKER_INITIALIZATION_ERROR\")"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 319,
      "end_line": 343,
      "signature": "async def start_workflow(\n    temporal_client: Client,\n    repo_request: RepositoryRequestConfiguration,\n    github_token: str,\n    workflow_id: str,\n    trace_id: str,\n) -> WorkflowHandle:",
      "docstring": "\n    Start a Temporal workflow for the given repository request and workflow id.\n    ",
      "function_calls": [
        "RepoWorkflowRunEnvelope(\n        repo_request=repo_request, github_token=github_token, trace_id=trace_id\n    )",
        "temporal_client.start_workflow(\n        RepoWorkflow.run,\n        arg=envelope,\n        id=workflow_id,\n        task_queue=\"unoplat-code-confluence-repository-context-ingestion\",\n    )",
        "logger.info(\n        \"Started workflow. Workflow ID: {}, RunID {}\",\n        workflow_handle.id,\n        workflow_handle.result_run_id,\n    )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 346,
      "end_line": 403,
      "signature": "async def detect_codebases_multi_language(\n    git_url: str,\n    github_token: str,\n    detectors: Dict[str, Any],\n    request_logger: \"Logger\",  # type: ignore\n) -> List[CodebaseConfig]:",
      "docstring": "\n    Detect codebases using all configured language detectors.\n\n    This function runs detection across all supported programming languages\n    (Python, TypeScript, etc.) and aggregates the results. It handles errors\n    gracefully by logging failures per language and continuing with other\n    detectors.\n\n    Args:\n        git_url: GitHub repository URL or local filesystem path\n        github_token: GitHub personal access token for authentication\n        detectors: Dictionary mapping language names to detector instances\n        request_logger: Logger instance for tracking detection progress\n\n    Returns:\n        List of detected CodebaseConfig across all languages\n\n    Raises:\n        HTTPException: If all detectors fail to find any codebases\n    ",
      "function_calls": [
        "detectors.items()",
        "request_logger.info(\n                \"Running {} codebase detection for {}\", language, git_url\n            )",
        "detector.detect_codebases(git_url, github_token)",
        "aggregated_codebases.extend(codebases)",
        "request_logger.info(\n                \"{} detection completed - found {} codebases\",\n                language.capitalize(),\n                len(codebases),\n            )",
        "language.capitalize()",
        "len(codebases)",
        "str(exc)",
        "request_logger.error(\n                \"Codebase detection failed | language={} | repo={} | error={}\",\n                language,\n                git_url,\n                exc,\n            )",
        "\"; \".join(f\"{lang}: {err}\" for lang, err in errors.items())",
        "errors.items()",
        "HTTPException(\n            status_code=500, detail=f\"All codebase detectors failed: {error_details}\"\n        )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 407,
      "end_line": 567,
      "signature": "@asynccontextmanager\nasync def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:",
      "docstring": null,
      "function_calls": [
        "EnvironmentSettings()",
        "get_temporal_client()",
        "CodeConfluenceGraph(\n        code_confluence_env=app.state.code_confluence_env\n    )",
        "app.state.code_confluence_graph.connect()",
        "app.state.code_confluence_graph.create_schema()",
        "logger.info(\"Neo4j connection and schema initialized successfully\")",
        "PythonRipgrepDetector()",
        "app.state.python_codebase_detector.initialize_rules()",
        "logger.info(\"PythonRipgrepDetector initialized successfully\")",
        "TypeScriptRipgrepDetector()",
        "app.state.typescript_codebase_detector.initialize_rules()",
        "logger.info(\"TypeScriptRipgrepDetector initialized successfully\")",
        "CodeConfluenceGraphDeletion(\n        app.state.code_confluence_graph\n    )",
        "ThreadPoolExecutor(max_workers=pool_size)",
        "logger.info(\n        \"Initialized activity executor with {} threads (max_concurrent_activities={} + 4 buffer threads)\",\n        pool_size,\n        app.state.code_confluence_env.temporal_max_concurrent_activities,\n    )",
        "asyncio.get_running_loop()",
        "loop.set_default_executor(app.state.activity_executor)",
        "logger.info(\"Set default executor for asyncio loop\")",
        "GitActivity()",
        "activities.append(git_activity.process_git_activity)",
        "ParentWorkflowDbActivity()",
        "activities.append(parent_workflow_db_activity.update_repository_workflow_status)",
        "ChildWorkflowDbActivity()",
        "activities.append(child_workflow_db_activity.update_codebase_workflow_status)",
        "PackageMetadataActivity()",
        "activities.append(package_metadata_activity.get_package_metadata)",
        "ConfluenceGitGraph(\n        code_confluence_graph=app.state.code_confluence_graph\n    )",
        "activities.append(confluence_git_graph.insert_git_repo_into_graph_db)",
        "PackageManagerMetadataIngestion(\n        code_confluence_graph=app.state.code_confluence_graph\n    )",
        "activities.append(codebase_package_ingestion.insert_package_manager_metadata)",
        "GenericCodebaseProcessingActivity(\n        code_confluence_graph=app.state.code_confluence_graph\n    )",
        "activities.append(generic_activity.process_codebase_generic)",
        "create_db_and_tables()",
        "os.getenv(\"LOAD_FRAMEWORK_DEFINITIONS\", \"true\").lower()",
        "os.getenv(\"LOAD_FRAMEWORK_DEFINITIONS\", \"true\")",
        "FrameworkDefinitionLoader(app.state.code_confluence_env)",
        "get_session_cm()",
        "framework_loader.load_framework_definitions_at_startup(\n                    session\n                )",
        "metrics.get(\"skipped\")",
        "logger.info(\n                        \"Framework definitions loaded in {:.3f}s\", metrics[\"total_time\"]\n                    )",
        "logger.error(\"Failed to load framework definitions: {}\", e)",
        "os.getenv(\"FRAMEWORK_DEFINITIONS_REQUIRED\", \"false\")",
        "os.getenv(\"FRAMEWORK_DEFINITIONS_REQUIRED\", \"false\").lower()",
        "create_worker(\n        activities=activities,\n        client=app.state.temporal_client,\n        activity_executor=app.state.activity_executor,\n        env_settings=app.state.code_confluence_env,\n    )",
        "asyncio.Event()",
        "asyncio.create_task(_serve_worker(stop_event, worker))",
        "_serve_worker(stop_event, worker)",
        "logger.info(\"Shutting down application...\")",
        "stop_event.set()",
        "logger.info(\"Temporal worker shut down successfully\")",
        "logger.error(\"Error during worker shutdown: {}\", e)",
        "app.state.code_confluence_graph.close()",
        "logger.info(\"Neo4j global connection closed\")",
        "logger.error(\"Error closing Neo4j connections: {}\", e)",
        "dispose_current_engine()",
        "logger.info(\"SQLAlchemy engine disposed\")",
        "logger.warning(\"Failed to dispose async engine during shutdown: {}\", exc)",
        "app.state.activity_executor.shutdown(wait=True)",
        "logger.info(\"Thread pool executor shut down\")",
        "logger.error(\"Error shutting down thread pool executor: {}\", e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 588,
      "end_line": 593,
      "signature": "async def monitor_workflow(workflow_handle: WorkflowHandle) -> None:",
      "docstring": null,
      "function_calls": [
        "workflow_handle.result()",
        "logger.info(\"Workflow completed with result: {}\", result)",
        "logger.error(\"Workflow failed: {}\", e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 596,
      "end_line": 664,
      "signature": "@app.post(\"/ingest-token\", status_code=201)\nasync def ingest_token(\n    authorization: str = Header(...),\n    namespace: CredentialNamespace = Query(..., description=\"Credential namespace\"),\n    provider_key: ProviderKey = Query(..., description=\"Provider key\"),\n    secret_kind: SecretKind = Query(..., description=\"Secret kind\"),\n    url: Optional[str] = Query(\n        None, description=\"Base URL for enterprise/self-hosted instances\"\n    ),\n    session: AsyncSession = Depends(get_session),\n) -> Dict[str, str]:",
      "docstring": null,
      "function_calls": [
        "Header(...)",
        "Query(..., description=\"Credential namespace\")",
        "Query(..., description=\"Provider key\")",
        "Query(..., description=\"Secret kind\")",
        "Query(\n        None, description=\"Base URL for enterprise/self-hosted instances\"\n    )",
        "Depends(get_session)",
        "authorization.startswith(\"Bearer \")",
        "HTTPException(status_code=401, detail=\"Invalid Authorization header\")",
        "authorization[7:].strip()",
        "encrypt_token(token)",
        "datetime.now(timezone.utc)",
        "session.execute(\n            select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)\n            .where(Credentials.secret_kind == secret_kind)\n        )",
        "select(Credentials)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)\n            .where(Credentials.secret_kind == secret_kind)",
        "result.scalars()",
        "result.scalars().first()",
        "HTTPException(\n                status_code=409,\n                detail=f\"Credential for {namespace.value}/{provider_key.value}/{secret_kind.value} already exists. Use update-token to update it.\",\n            )",
        "Credentials(\n            namespace=namespace,\n            provider_key=provider_key,\n            secret_kind=secret_kind,\n            token_hash=encrypted_token,\n            metadata_json=metadata,\n            created_at=current_time,\n            updated_at=current_time,\n        )",
        "session.add(credential)",
        "session.execute(\n            select(Flag).where(Flag.name == \"isTokenSubmitted\")\n        )",
        "select(Flag).where(Flag.name == \"isTokenSubmitted\")",
        "select(Flag)",
        "flag_result.scalar_one_or_none()",
        "Flag(name=\"isTokenSubmitted\", status=True)",
        "session.add(token_flag)",
        "logger.error(\"Failed to process token: {}\", str(e))",
        "str(e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 667,
      "end_line": 715,
      "signature": "@app.put(\"/update-token\", status_code=200)\nasync def update_token(\n    authorization: str = Header(...),\n    namespace: CredentialNamespace = Query(..., description=\"Credential namespace\"),\n    provider_key: ProviderKey = Query(..., description=\"Provider key\"),\n    secret_kind: SecretKind = Query(..., description=\"Secret kind\"),\n    url: Optional[str] = Query(\n        None, description=\"Base URL for enterprise/self-hosted instances\"\n    ),\n    session: AsyncSession = Depends(get_session),\n) -> Dict[str, str]:",
      "docstring": null,
      "function_calls": [
        "Header(...)",
        "Query(..., description=\"Credential namespace\")",
        "Query(..., description=\"Provider key\")",
        "Query(..., description=\"Secret kind\")",
        "Query(\n        None, description=\"Base URL for enterprise/self-hosted instances\"\n    )",
        "Depends(get_session)",
        "authorization.startswith(\"Bearer \")",
        "HTTPException(status_code=401, detail=\"Invalid Authorization header\")",
        "authorization[7:].strip()",
        "encrypt_token(token)",
        "datetime.now(timezone.utc)",
        "session.execute(\n            select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)\n            .where(Credentials.secret_kind == secret_kind)\n        )",
        "select(Credentials)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)\n            .where(Credentials.secret_kind == secret_kind)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)",
        "result.scalars()",
        "result.scalars().first()",
        "HTTPException(\n                status_code=404,\n                detail=f\"No credential found for {namespace.value}/{provider_key.value}/{secret_kind.value}\",\n            )",
        "session.add(credential)",
        "logger.error(\"Failed to update token: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=\"Failed to update authentication token\"\n        )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 718,
      "end_line": 759,
      "signature": "def get_github_graphql_url(\n    provider_key: ProviderKey, metadata: Optional[Dict[str, Any]]\n) -> str:",
      "docstring": "\n    Get GitHub GraphQL API endpoint URL.\n\n    Supports:\n    - GitHub.com (GITHUB_OPEN): https://api.github.com/graphql\n    - Enterprise Server (GITHUB_ENTERPRISE + URL): https://HOSTNAME/api/graphql\n    - Enterprise Cloud standard (GITHUB_ENTERPRISE, no URL): https://api.github.com/graphql\n    - Enterprise Cloud data residency (GITHUB_ENTERPRISE + ghe.com): https://api.SUBDOMAIN.ghe.com/graphql\n\n    Args:\n        provider_key: Provider key (GITHUB_OPEN or GITHUB_ENTERPRISE)\n        metadata: Metadata containing base URL for enterprise instances\n\n    Returns:\n        GitHub GraphQL API endpoint URL\n\n    Raises:\n        HTTPException: If enterprise configuration is invalid\n    ",
      "function_calls": [
        "metadata[\"url\"].rstrip(\"/\")",
        "base_url.replace(\"https://\", \"\")",
        "base_url.replace(\"https://\", \"\").replace(\"http://\", \"\")"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 762,
      "end_line": 803,
      "signature": "def get_github_rest_api_base_url(\n    provider_key: ProviderKey, metadata: Optional[Dict[str, Any]]\n) -> str:",
      "docstring": "\n    Get GitHub REST API base URL based on provider type.\n\n    Supports:\n    - GitHub.com (GITHUB_OPEN): https://api.github.com\n    - Enterprise Server (GITHUB_ENTERPRISE + URL): https://HOSTNAME/api/v3\n    - Enterprise Cloud standard (GITHUB_ENTERPRISE, no URL): https://api.github.com\n    - Enterprise Cloud data residency (GITHUB_ENTERPRISE + ghe.com): https://api.SUBDOMAIN.ghe.com\n\n    Args:\n        provider_key: Provider key (GITHUB_OPEN or GITHUB_ENTERPRISE)\n        metadata: Metadata containing base URL for enterprise instances\n\n    Returns:\n        GitHub REST API base URL\n\n    Raises:\n        HTTPException: If enterprise configuration is invalid\n    ",
      "function_calls": [
        "metadata[\"url\"].rstrip(\"/\")",
        "base_url.replace(\"https://\", \"\").replace(\"http://\", \"\")",
        "base_url.replace(\"https://\", \"\")"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 806,
      "end_line": 845,
      "signature": "def build_repository_git_url(\n    repository_owner_name: str,\n    repository_name: str,\n    provider_key: ProviderKey,\n    metadata: Optional[Dict[str, Any]],\n) -> str:",
      "docstring": "\n    Construct the git clone URL for a repository based on provider configuration.\n\n    Args:\n        repository_owner_name: Repository owner/organization name\n        repository_name: Repository name\n        provider_key: Provider key (GITHUB_OPEN or GITHUB_ENTERPRISE)\n        metadata: Metadata containing base URL for enterprise instances\n\n    Returns:\n        Git clone URL (HTTPS format)\n\n    Raises:\n        HTTPException: If repository details or enterprise configuration is invalid\n    ",
      "function_calls": [
        "repository_owner_name.strip()",
        "repository_name.strip()",
        "HTTPException(\n            status_code=400,\n            detail=\"Repository owner and name are required to build git URL\",\n        )",
        "metadata.get(\"url\")",
        "metadata[\"url\"].rstrip(\"/\")"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 848,
      "end_line": 895,
      "signature": "@app.delete(\"/delete-token\", status_code=200)\nasync def delete_token(\n    namespace: CredentialNamespace = Query(..., description=\"Credential namespace\"),\n    provider_key: ProviderKey = Query(..., description=\"Provider key\"),\n    secret_kind: SecretKind = Query(..., description=\"Secret kind\"),\n    session: AsyncSession = Depends(get_session),\n) -> Dict[str, str]:",
      "docstring": null,
      "function_calls": [
        "Query(..., description=\"Credential namespace\")",
        "Query(..., description=\"Provider key\")",
        "Query(..., description=\"Secret kind\")",
        "Depends(get_session)",
        "session.execute(\n            select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)\n            .where(Credentials.secret_kind == secret_kind)\n        )",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)\n            .where(Credentials.provider_key == provider_key)\n            .where(Credentials.secret_kind == secret_kind)",
        "select(Credentials)",
        "select(Credentials)\n            .where(Credentials.namespace == namespace)",
        "result.scalars().first()",
        "result.scalars()",
        "HTTPException(\n                status_code=404,\n                detail=f\"No credential found for {namespace.value}/{provider_key.value}/{secret_kind.value}\",\n            )",
        "session.delete(credential)",
        "session.execute(\n            select(Flag).where(Flag.name == \"isTokenSubmitted\")\n        )",
        "select(Flag)",
        "select(Flag).where(Flag.name == \"isTokenSubmitted\")",
        "flag_result.scalar_one_or_none()",
        "Flag(name=\"isTokenSubmitted\", status=False)",
        "session.add(token_flag)",
        "logger.error(\"Failed to delete token: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=\"Failed to delete authentication token\"\n        )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 898,
      "end_line": 920,
      "signature": "@app.get(\"/repository-providers\", response_model=RepositoryProvidersResponse)\nasync def get_repository_providers(\n    session: AsyncSession = Depends(get_session),\n) -> RepositoryProvidersResponse:",
      "docstring": "Get all configured repository providers from credentials table.",
      "function_calls": [
        "Depends(get_session)",
        "session.execute(\n            select(Credentials)\n            .where(Credentials.namespace == CredentialNamespace.REPOSITORY)\n            .where(Credentials.secret_kind == SecretKind.PAT)\n        )",
        "select(Credentials)\n            .where(Credentials.namespace == CredentialNamespace.REPOSITORY)\n            .where(Credentials.secret_kind == SecretKind.PAT)",
        "select(Credentials)\n            .where(Credentials.namespace == CredentialNamespace.REPOSITORY)",
        "select(Credentials)",
        "result.scalars().all()",
        "result.scalars()",
        "RepositoryProvidersResponse(providers=provider_keys)",
        "logger.error(\"Failed to fetch repository providers: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=\"Failed to fetch repository providers\"\n        )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 923,
      "end_line": 1075,
      "signature": "@app.get(\"/repos\", response_model=PaginatedResponse)\nasync def get_repos(\n    per_page: int = Query(30, ge=1, le=100, description=\"Items per page\"),\n    cursor: Optional[str] = Query(None, description=\"Pagination cursor\"),\n    filterValues: Optional[str] = Query(\n        None, description=\"Optional JSON filter values to filter repositories\"\n    ),\n    provider_key: ProviderKey = Query(..., description=\"Repository provider key\"),\n    session: AsyncSession = Depends(get_session),\n) -> PaginatedResponse:",
      "docstring": null,
      "function_calls": [
        "Query(30, ge=1, le=100, description=\"Items per page\")",
        "Query(None, description=\"Pagination cursor\")",
        "Query(\n        None, description=\"Optional JSON filter values to filter repositories\"\n    )",
        "Query(..., description=\"Repository provider key\")",
        "Depends(get_session)",
        "fetch_repository_provider_token(\n        session, CredentialNamespace.REPOSITORY, provider_key\n    )",
        "json.loads(filterValues)",
        "logger.error(\"Invalid JSON in filterValues: {}\", e)",
        "HTTPException(\n                status_code=400, detail=\"Invalid JSON in filterValues query parameter\"\n            )",
        "get_github_graphql_url(provider_key, metadata)",
        "AIOHTTPTransport(\n            url=graphql_url,\n            headers={\n                \"Authorization\": f\"Bearer {token}\",\n                \"User-Agent\": \"Unoplat Code Confluence\",\n            },\n        )",
        "GQLClient(\n            transport=transport,\n            fetch_schema_from_transport=False,\n        )",
        "gql(\n                    \"\"\"\n                    query SearchRepositories($query: String!, $first: Int!, $after: String) {\n                        search(query: $query, type: REPOSITORY, first: $first, after: $after) {\n                            pageInfo {\n                                endCursor\n                                hasNextPage\n                            }\n                            nodes {\n                                ... on Repository {\n                                    name\n                                    isPrivate\n                                    url\n                                    owner {\n                                        login\n                                        url\n                                    }\n                                }\n                            }\n                        }\n                    }\n                    \"\"\"\n                )",
        "client.execute(\n                    query,\n                    variable_values={\n                        \"query\": search_query,\n                        \"first\": per_page,\n                        \"after\": cursor,\n                    },\n                )",
        "gql(\n                    \"\"\"\n                    query GetRepositories($first: Int!, $after: String) {\n                        viewer {\n                            repositories(\n                                first: $first,\n                                affiliations: [OWNER, COLLABORATOR, ORGANIZATION_MEMBER],\n                                after: $after\n                            ) {\n                                pageInfo {\n                                    endCursor\n                                    hasNextPage\n                                }\n                                nodes {\n                                    name\n                                    isPrivate\n                                    url\n                                    owner {\n                                        login\n                                        url\n                                    }\n                                }\n                            }\n                        }\n                    }\n                    \"\"\"\n                )",
        "client.execute(\n                    query, variable_values={\"first\": per_page, \"after\": cursor}\n                )",
        "GitHubRepoSummary(\n                    name=item[\"name\"],\n                    owner_url=item[\"owner\"][\"url\"],\n                    private=item[\"isPrivate\"],\n                    git_url=item[\"url\"],\n                    owner_name=item[\"owner\"][\"login\"],\n                )",
        "repos_list.append(repo_summary)",
        "PaginatedResponse(\n                items=repos_list,\n                per_page=per_page,\n                has_next=has_next,\n                next_cursor=next_cursor,\n            )",
        "logger.error(\"GraphQL Error: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=f\"Failed to fetch repositories: {str(e)}\"\n        )",
        "str(e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1078,
      "end_line": 1147,
      "signature": "@app.post(\"/start-ingestion\", status_code=201)\nasync def ingestion(\n    repo_request: RepositoryRequestConfiguration,\n    session: AsyncSession = Depends(get_session),\n    request_logger: \"Logger\" = Depends(trace_dependency),  # type: ignore\n) -> dict[str, str]:",
      "docstring": "\n    Start the ingestion workflow for the entire repository using the repository provider token from the database.\n    Submits the whole repo_request at once to the Temporal workflow.\n    Returns the workflow_id and run_id.\n    Also ingests the repository configuration into the database.\n    ",
      "function_calls": [
        "Depends(get_session)",
        "Depends(trace_dependency)",
        "fetch_repository_provider_token(\n        session, CredentialNamespace.REPOSITORY, repo_request.provider_key\n    )",
        "len(repo_request.repository_metadata)",
        "request_logger.info(\n            \"No codebases provided - starting auto-detection for {}/{}\",\n            repo_request.repository_owner_name,\n            repo_request.repository_name,\n        )",
        "detect_codebases_multi_language(\n            git_url=repo_request.repository_git_url,\n            github_token=github_token,\n            detectors=app.state.codebase_detectors,\n            request_logger=request_logger,\n        )",
        "request_logger.info(\n            \"Auto-detection completed - found {} codebases\", len(detected_codebases)\n        )",
        "len(detected_codebases)",
        "request_logger.info(\n            \"Using provided codebases - count: {}\",\n            len(repo_request.repository_metadata),\n        )",
        "len(repo_request.repository_metadata)",
        "trace_id_var.get()",
        "HTTPException(500, \"trace_id not set by dependency\")",
        "start_workflow(\n        temporal_client=app.state.temporal_client,\n        repo_request=repo_request,\n        github_token=github_token,\n        workflow_id=f\"ingest-{repo_request.provider_key.value}-{trace_id}\",\n        trace_id=trace_id,\n    )",
        "asyncio.create_task(monitor_workflow(workflow_handle))",
        "monitor_workflow(workflow_handle)",
        "request_logger.info(\n        \"Started workflow. Workflow ID: {}, RunID {}\",\n        workflow_handle.id,\n        workflow_handle.result_run_id,\n    )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1150,
      "end_line": 1177,
      "signature": "@app.get(\"/flags/{flag_name}\", status_code=200)\nasync def get_flag_status(\n    flag_name: str, session: AsyncSession = Depends(get_session)\n) -> Dict[str, Any]:",
      "docstring": "\n    Get the status of a specific flag by name.\n\n    Args:\n        flag_name (str): The name of the flag to check\n        session (Session): Database session\n\n    Returns:\n        Dict[str, Any]: Flag information including status\n    ",
      "function_calls": [
        "Depends(get_session)",
        "session.execute(select(Flag).where(Flag.name == flag_name))",
        "select(Flag).where(Flag.name == flag_name)",
        "select(Flag)",
        "result.scalar_one_or_none()",
        "HTTPException(status_code=404, detail=f\"Flag '{flag_name}' not found\")",
        "logger.error(\"Failed to get flag status: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=\"Failed to get flag status for {}\".format(flag_name)\n        )",
        "\"Failed to get flag status for {}\".format(flag_name)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1180,
      "end_line": 1199,
      "signature": "@app.get(\"/flags\", status_code=200)\nasync def get_all_flags(\n    session: AsyncSession = Depends(get_session),\n) -> List[Dict[str, Any]]:",
      "docstring": "\n    Get the status of all available flags.\n\n    Args:\n        session (Session): Database session\n\n    Returns:\n        List[Dict[str, Any]]: List of flag information\n    ",
      "function_calls": [
        "Depends(get_session)",
        "session.execute(select(Flag))",
        "select(Flag)",
        "result.scalars().all()",
        "result.scalars()",
        "logger.error(\"Failed to get flags: {}\", str(e))",
        "str(e)",
        "HTTPException(status_code=500, detail=\"Failed to get flags\")"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1202,
      "end_line": 1235,
      "signature": "@app.put(\"/flags/{flag_name}\", status_code=200)\nasync def set_flag_status(\n    flag_name: str, status: bool, session: AsyncSession = Depends(get_session)\n) -> Dict[str, Any]:",
      "docstring": "\n    Set the status of a specific flag by name.\n\n    Args:\n        flag_name (str): The name of the flag to set\n        status (bool): The status to set for the flag\n        session (Session): Database session\n\n    Returns:\n        Dict[str, Any]: Updated flag information\n    ",
      "function_calls": [
        "Depends(get_session)",
        "session.execute(select(Flag).where(Flag.name == flag_name))",
        "select(Flag)",
        "select(Flag).where(Flag.name == flag_name)",
        "result.scalar_one_or_none()",
        "Flag(name=flag_name, status=status)",
        "session.add(flag)",
        "logger.error(\"Failed to set flag status: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=\"Failed to set flag status for {}\".format(flag_name)\n        )",
        "\"Failed to set flag status for {}\".format(flag_name)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1238,
      "end_line": 1357,
      "signature": "@app.get(\n    \"/repository-status\",\n    response_model=GithubRepoStatus,\n)\nasync def get_repository_status(\n    repository_name: str = Query(..., description=\"The name of the repository\"),\n    repository_owner_name: str = Query(\n        ..., description=\"The name of the repository owner\"\n    ),\n    workflow_run_id: str = Query(\n        ..., description=\"The workflow run ID to fetch status for\"\n    ),\n    session: AsyncSession = Depends(get_session),\n) -> GithubRepoStatus:",
      "docstring": "\n    Get the current status of a repository workflow run and its associated codebase runs.\n    ",
      "function_calls": [
        "Query(..., description=\"The name of the repository\")",
        "Query(\n        ..., description=\"The name of the repository owner\"\n    )",
        "Query(\n        ..., description=\"The workflow run ID to fetch status for\"\n    )",
        "Depends(get_session)",
        "select(RepositoryWorkflowRun).where(\n            RepositoryWorkflowRun.repository_name == repository_name,\n            RepositoryWorkflowRun.repository_owner_name == repository_owner_name,\n            RepositoryWorkflowRun.repository_workflow_run_id == workflow_run_id,\n        )",
        "select(RepositoryWorkflowRun)",
        "(await session.execute(stmt)).scalar_one_or_none()",
        "session.execute(stmt)",
        "\"Workflow run {} not found for {}/{}\".format(\n                workflow_run_id, repository_name, repository_owner_name\n            )",
        "HTTPException(status_code=404, detail=error_msg)",
        "select(CodebaseWorkflowRun)",
        "select(CodebaseWorkflowRun).where(\n            CodebaseWorkflowRun.repository_name == repository_name,\n            CodebaseWorkflowRun.repository_owner_name == repository_owner_name,\n            CodebaseWorkflowRun.repository_workflow_run_id\n            == parent_run.repository_workflow_run_id,\n        )",
        "(await session.execute(cb_stmt)).scalars()",
        "(await session.execute(cb_stmt)).scalars().all()",
        "session.execute(cb_stmt)",
        "ErrorReport(**run.error_report)",
        "WorkflowRun(\n                codebase_workflow_run_id=run.codebase_workflow_run_id,\n                status=JobStatus(run.status),\n                started_at=run.started_at,\n                completed_at=run.completed_at,\n                error_report=error_report,\n                issue_tracking=IssueTracking(**run.issue_tracking)\n                if run.issue_tracking\n                else None,\n            )",
        "JobStatus(run.status)",
        "IssueTracking(**run.issue_tracking)",
        "codebase_data[codebase_folder].append(\n                (run.codebase_workflow_id, workflow_run)\n            )",
        "codebase_data.items()",
        "workflow_map[workflow_id].append(wf_run)",
        "workflow_map.items()",
        "workflows.append(\n                    WorkflowStatus(\n                        codebase_workflow_id=workflow_id,\n                        codebase_workflow_runs=workflow_runs,\n                    )\n                )",
        "WorkflowStatus(\n                        codebase_workflow_id=workflow_id,\n                        codebase_workflow_runs=workflow_runs,\n                    )",
        "codebases.append(\n                CodebaseStatus(codebase_folder=codebase_folder, workflows=workflows)\n            )",
        "CodebaseStatus(codebase_folder=codebase_folder, workflows=workflows)",
        "CodebaseStatusList(codebases=codebases)",
        "GithubRepoStatus(\n            repository_name=parent_run.repository_name,\n            repository_owner_name=parent_run.repository_owner_name,\n            repository_workflow_run_id=parent_run.repository_workflow_run_id,\n            repository_workflow_id=parent_run.repository_workflow_id,\n            issue_tracking=IssueTracking(**parent_run.issue_tracking)\n            if parent_run.issue_tracking\n            else None,\n            status=JobStatus(parent_run.status),\n            started_at=parent_run.started_at,\n            completed_at=parent_run.completed_at,\n            error_report=ErrorReport(**parent_run.error_report)\n            if parent_run.error_report\n            else None,\n            codebase_status_list=codebase_status_list,\n        )",
        "IssueTracking(**parent_run.issue_tracking)",
        "JobStatus(parent_run.status)",
        "ErrorReport(**parent_run.error_report)",
        "logger.error(\"Error retrieving repository status: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500,\n            detail=\"Error retrieving repository status: {}\".format(str(e)),\n        )",
        "\"Error retrieving repository status: {}\".format(str(e))",
        "str(e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1360,
      "end_line": 1416,
      "signature": "@app.get(\n    \"/repository-data\",\n    response_model=GitHubRepoResponseConfiguration,\n)\nasync def get_repository_data(\n    repository_name: str = Query(..., description=\"The name of the repository\"),\n    repository_owner_name: str = Query(\n        ..., description=\"The name of the repository owner\"\n    ),\n    session: AsyncSession = Depends(get_session),\n) -> GitHubRepoResponseConfiguration:",
      "docstring": null,
      "function_calls": [
        "Query(..., description=\"The name of the repository\")",
        "Query(\n        ..., description=\"The name of the repository owner\"\n    )",
        "Depends(get_session)",
        "session.get(\n        Repository,\n        (repository_name, repository_owner_name),\n        options=[selectinload(cast(QueryableAttribute[Any], Repository.configs))],\n    )",
        "selectinload(cast(QueryableAttribute[Any], Repository.configs))",
        "cast(QueryableAttribute[Any], Repository.configs)",
        "HTTPException(\n            status_code=404,\n            detail=\"Repository data not found for {}/{}\".format(\n                repository_name, repository_owner_name\n            ),\n        )",
        "\"Repository data not found for {}/{}\".format(\n                repository_name, repository_owner_name\n            )",
        "CodebaseConfig(\n                codebase_folder=config.codebase_folder,\n                root_packages=config.root_packages,\n                programming_language_metadata=ProgrammingLanguageMetadata(\n                    language=config.programming_language_metadata[\"language\"],\n                    package_manager=config.programming_language_metadata[\n                        \"package_manager\"\n                    ],\n                    language_version=config.programming_language_metadata.get(\n                        \"language_version\"\n                    ),\n                ),\n            )",
        "ProgrammingLanguageMetadata(\n                    language=config.programming_language_metadata[\"language\"],\n                    package_manager=config.programming_language_metadata[\n                        \"package_manager\"\n                    ],\n                    language_version=config.programming_language_metadata.get(\n                        \"language_version\"\n                    ),\n                )",
        "config.programming_language_metadata.get(\n                        \"language_version\"\n                    )",
        "GitHubRepoResponseConfiguration(\n            repository_name=db_obj.repository_name,\n            repository_owner_name=db_obj.repository_owner_name,\n            repository_metadata=codebases,\n        )",
        "logger.error(\"Error mapping repository data: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500,\n            detail=\"Error processing repository data for {}/{}\".format(\n                repository_name, repository_owner_name\n            ),\n        )",
        "\"Error processing repository data for {}/{}\".format(\n                repository_name, repository_owner_name\n            )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1419,
      "end_line": 1487,
      "signature": "@app.get(\n    \"/codebase-metadata\",\n    response_model=CodebaseMetadataListResponse,\n)\nasync def get_codebase_metadata(\n    repository_name: str = Query(..., description=\"The name of the repository\"),\n    repository_owner_name: str = Query(\n        ..., description=\"The name of the repository owner\"\n    ),\n    session: AsyncSession = Depends(get_session),\n) -> CodebaseMetadataListResponse:",
      "docstring": "\n    Get codebase folders and their metadata for a specific repository.\n\n    Returns a list of all codebases configured for the repository with their\n    folder paths and programming language metadata.\n    ",
      "function_calls": [
        "Query(..., description=\"The name of the repository\")",
        "Query(\n        ..., description=\"The name of the repository owner\"\n    )",
        "Depends(get_session)",
        "session.get(\n        Repository,\n        (repository_name, repository_owner_name),\n        options=[selectinload(cast(QueryableAttribute[Any], Repository.configs))],\n    )",
        "selectinload(cast(QueryableAttribute[Any], Repository.configs))",
        "cast(QueryableAttribute[Any], Repository.configs)",
        "HTTPException(\n            status_code=404,\n            detail=\"Repository not found: {}/{}\".format(\n                repository_owner_name, repository_name\n            ),\n        )",
        "\"Repository not found: {}/{}\".format(\n                repository_owner_name, repository_name\n            )",
        "CodebaseMetadataResponse(\n                codebase_folder=config.codebase_folder,\n                programming_language_metadata=ProgrammingLanguageMetadata(\n                    language=config.programming_language_metadata[\"language\"],\n                    package_manager=config.programming_language_metadata.get(\n                        \"package_manager\"\n                    ),\n                    language_version=config.programming_language_metadata.get(\n                        \"language_version\"\n                    ),\n                    manifest_path=config.programming_language_metadata.get(\n                        \"manifest_path\"\n                    ),\n                    project_name=config.programming_language_metadata.get(\n                        \"project_name\"\n                    ),\n                ),\n            )",
        "ProgrammingLanguageMetadata(\n                    language=config.programming_language_metadata[\"language\"],\n                    package_manager=config.programming_language_metadata.get(\n                        \"package_manager\"\n                    ),\n                    language_version=config.programming_language_metadata.get(\n                        \"language_version\"\n                    ),\n                    manifest_path=config.programming_language_metadata.get(\n                        \"manifest_path\"\n                    ),\n                    project_name=config.programming_language_metadata.get(\n                        \"project_name\"\n                    ),\n                )",
        "config.programming_language_metadata.get(\n                        \"package_manager\"\n                    )",
        "config.programming_language_metadata.get(\n                        \"language_version\"\n                    )",
        "config.programming_language_metadata.get(\n                        \"manifest_path\"\n                    )",
        "config.programming_language_metadata.get(\n                        \"project_name\"\n                    )",
        "CodebaseMetadataListResponse(\n            repository_name=db_obj.repository_name,\n            repository_owner_name=db_obj.repository_owner_name,\n            codebases=codebase_metadata,\n        )",
        "logger.error(\"Error mapping codebase metadata: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500,\n            detail=\"Error processing codebase metadata for {}/{}\".format(\n                repository_owner_name, repository_name\n            ),\n        )",
        "\"Error processing codebase metadata for {}/{}\".format(\n                repository_owner_name, repository_name\n            )"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1490,
      "end_line": 1530,
      "signature": "@app.get(\n    \"/parent-workflow-jobs\",\n    response_model=ParentWorkflowJobListResponse,\n    description=\"Get all parent workflow jobs data without pagination\",\n)\nasync def get_parent_workflow_jobs(\n    session: AsyncSession = Depends(get_session),\n) -> ParentWorkflowJobListResponse:",
      "docstring": "Get all parent workflow jobs data without pagination.\n\n    Returns job information for all parent workflows (RepositoryWorkflowRun).\n    Includes repository_name, repository_owner_name, repository_workflow_run_id, operation, status, started_at, completed_at.\n    ",
      "function_calls": [
        "Depends(get_session)",
        "select(RepositoryWorkflowRun)",
        "session.execute(query)",
        "result.scalars()",
        "result.scalars().all()",
        "ParentWorkflowJobResponse(\n                repository_name=run.repository_name,\n                repository_owner_name=run.repository_owner_name,\n                repository_workflow_run_id=run.repository_workflow_run_id,\n                operation=run.operation,\n                status=JobStatus(run.status),\n                started_at=run.started_at,\n                completed_at=run.completed_at,\n                feedback_issue_url=run.feedback_issue_url,\n            )",
        "JobStatus(run.status)",
        "ParentWorkflowJobListResponse(jobs=jobs)",
        "logger.error(\"Error retrieving parent workflow jobs: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500,\n            detail=\"Error retrieving parent workflow jobs: {}\".format(str(e)),\n        )",
        "\"Error retrieving parent workflow jobs: {}\".format(str(e))",
        "str(e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1533,
      "end_line": 1568,
      "signature": "@app.get(\n    \"/get/ingestedRepositories\",\n    response_model=IngestedRepositoriesListResponse,\n    description=\"Get all ingested repositories without pagination\",\n)\nasync def get_ingested_repositories(\n    session: AsyncSession = Depends(get_session),\n) -> IngestedRepositoriesListResponse:",
      "docstring": "Get all ingested repositories without pagination.\n\n    Returns basic information for all repositories in the database.\n    Includes repository_name and repository_owner_name only.\n    ",
      "function_calls": [
        "Depends(get_session)",
        "select(Repository)",
        "session.execute(query)",
        "result.scalars().all()",
        "result.scalars()",
        "IngestedRepositoryResponse(\n                repository_name=repo.repository_name,\n                repository_owner_name=repo.repository_owner_name,\n                provider_key=repo.repository_provider,\n            )",
        "IngestedRepositoriesListResponse(repositories=repo_list)",
        "logger.error(\"Error retrieving ingested repositories: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500,\n            detail=\"Error retrieving ingested repositories: {}\".format(str(e)),\n        )",
        "\"Error retrieving ingested repositories: {}\".format(str(e))",
        "str(e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1571,
      "end_line": 1664,
      "signature": "@app.delete(\"/delete-repository\", status_code=200)\nasync def delete_repository(\n    repo_info: IngestedRepositoryResponse, session: AsyncSession = Depends(get_session)\n) -> Dict[str, Any]:",
      "docstring": "Delete a repository from both PostgreSQL and Neo4j databases.\n\n    This endpoint removes a repository and all its associated data including:\n    - Repository record and cascaded relations in PostgreSQL\n    - Repository node and all connected nodes/relationships in Neo4j\n\n    Args:\n        repo_info: IngestedRepositoryResponse containing repository_name and repository_owner_name\n        session: Database session\n\n    Returns:\n        Success message with deletion statistics\n\n    Raises:\n        HTTPException: 404 if repository not found, 500 on error\n    ",
      "function_calls": [
        "Depends(get_session)",
        "session.get(\n            Repository, (repository_name, repository_owner_name)\n        )",
        "HTTPException(\n                status_code=404,\n                detail=\"Repository not found: {}/{}\".format(\n                    repository_owner_name, repository_name\n                ),\n            )",
        "\"Repository not found: {}/{}\".format(\n                    repository_owner_name, repository_name\n                )",
        "session.delete(db_obj)",
        "session.commit()",
        "logger.info(\n            \"Deleted repository from PostgreSQL: {}/{}\",\n            repository_owner_name,\n            repository_name,\n        )",
        "\"{}_{}\".format(repository_owner_name, repository_name)",
        "app.state.code_confluence_graph.get_session()",
        "app.state.code_confluence_graph_deletion.delete_repository_by_qualified_name_managed(\n                    session=neo4j_session, qualified_name=qualified_name\n                )",
        "logger.info(\"Deleted repository from Neo4j: {}\", qualified_name)",
        "logger.warning(\n                    \"Repository not found in Neo4j (may have been already deleted): {}\",\n                    qualified_name,\n                )",
        "\"Successfully deleted repository {}/{}\".format(\n                repository_owner_name, repository_name\n            )",
        "logger.error(\"Neo4j deletion error: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500,\n            detail=\"Failed to delete repository from graph database: {}\".format(str(e)),\n        )",
        "\"Failed to delete repository from graph database: {}\".format(str(e))",
        "str(e)",
        "logger.error(\"Error deleting repository: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=\"Error deleting repository: {}\".format(str(e))\n        )",
        "\"Error deleting repository: {}\".format(str(e))",
        "str(e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1667,
      "end_line": 1820,
      "signature": "@app.post(\n    \"/refresh-repository\", response_model=RefreshRepositoryResponse, status_code=201\n)\nasync def refresh_repository(\n    refresh_request: RepositoryRefreshRequest,\n    session: AsyncSession = Depends(get_session),\n    request_logger: \"Logger\" = Depends(trace_dependency),  # type: ignore\n) -> RefreshRepositoryResponse:",
      "docstring": "\n    Refresh a repository by purging Neo4j data and re-ingesting.\n\n    This endpoint:\n    1. Deletes all repository data from Neo4j (keeps PostgreSQL intact)\n    2. Re-detects codebases using configured detectors\n    3. Starts a new Temporal workflow for ingestion\n\n    Args:\n        repo_request: Repository request configuration with provider_key\n        session: Database session\n        request_logger: Logger with trace ID\n\n    Returns:\n        RefreshRepositoryResponse with workflow IDs\n    ",
      "function_calls": [
        "Depends(get_session)",
        "Depends(trace_dependency)",
        "session.get(\n            Repository, (repository_name, repository_owner_name)\n        )",
        "HTTPException(\n                status_code=404,\n                detail=\"Repository not found in database: {}/{}\".format(\n                    repository_name, repository_owner_name\n                ),\n            )",
        "\"Repository not found in database: {}/{}\".format(\n                    repository_name, repository_owner_name\n                )",
        "request_logger.warning(\n                \"Provider key mismatch for %s/%s: request=%s, db=%s\",\n                repository_owner_name,\n                repository_name,\n                provider_key,\n                db_repo.repository_provider,\n            )",
        "\"{}_{}\".format(repository_owner_name, repository_name)",
        "app.state.code_confluence_graph.get_session()",
        "app.state.code_confluence_graph_deletion.delete_repository_by_qualified_name_managed(\n                    session=neo4j_session, qualified_name=qualified_name\n                )",
        "request_logger.info(\"Deleted repository from Neo4j: {}\", qualified_name)",
        "request_logger.warning(\n                    \"Repository not found in Neo4j: {}\", qualified_name\n                )",
        "HTTPException(\n                    status_code=500, detail=f\"Neo4j deletion failed: {str(neo4j_error)}\"\n                )",
        "str(neo4j_error)",
        "fetch_repository_provider_token(\n            session, CredentialNamespace.REPOSITORY, provider_key\n        )",
        "build_repository_git_url(\n            repository_owner_name=repository_owner_name,\n            repository_name=repository_name,\n            provider_key=provider_key,\n            metadata=metadata,\n        )",
        "request_logger.info(\"Refreshing repository: {}\", repository_url)",
        "RepositoryRequestConfiguration(\n            repository_name=repository_name,\n            repository_owner_name=repository_owner_name,\n            repository_git_url=repository_url,\n            provider_key=provider_key,\n        )",
        "detect_codebases_multi_language(\n                git_url=repository_url,\n                github_token=provider_token,\n                detectors=app.state.codebase_detectors,\n                request_logger=request_logger,\n            )",
        "request_logger.info(\n                \"Detected {} codebases for {}/{}\",\n                len(detected_codebases),\n                repository_owner_name,\n                repository_name,\n            )",
        "len(detected_codebases)",
        "request_logger.error(\"Codebase detection failed: {}\", str(e))",
        "str(e)",
        "HTTPException(\n                status_code=500, detail=f\"Failed to detect codebases: {str(e)}\"\n            )",
        "str(e)",
        "trace_id_var.get()",
        "HTTPException(500, \"trace_id not set by dependency\")",
        "start_workflow(\n            temporal_client=app.state.temporal_client,\n            repo_request=repo_request,\n            github_token=provider_token,\n            workflow_id=f\"refresh-{provider_key.value}-{repository_owner_name}-{repository_name}-{trace_id}\",\n            trace_id=trace_id,\n        )",
        "asyncio.create_task(monitor_workflow(workflow_handle))",
        "monitor_workflow(workflow_handle)",
        "request_logger.info(\n            f\"Started refresh workflow for {repository_owner_name}/{repository_name}. \"\n            f\"Workflow ID: {workflow_handle.id}, RunID: {workflow_handle.result_run_id}\"\n        )",
        "RefreshRepositoryResponse(\n            repository_name=repository_name,\n            repository_owner_name=repository_owner_name,\n            workflow_id=workflow_handle.id or \"\",\n            run_id=workflow_handle.result_run_id or \"\",\n        )",
        "request_logger.error(\"Error refreshing repository: {}\", str(e))",
        "str(e)",
        "HTTPException(\n            status_code=500, detail=f\"Error refreshing repository: {str(e)}\"\n        )",
        "str(e)"
      ],
      "nested_functions": [],
      "instance_variables": []
    },
    {
      "start_line": 1823,
      "end_line": 1877,
      "signature": "@app.get(\"/user-details\", status_code=200)\nasync def get_user_details(\n    provider_key: ProviderKey = Query(..., description=\"Repository provider key\"),\n    session: AsyncSession = Depends(get_session),\n) -> Dict[str, Optional[str]]:",
      "docstring": "\n    Fetch authenticated GitHub user's name, avatar URL, and email.\n    ",
      "function_calls": [
        "Query(..., description=\"Repository provider key\")",
        "Depends(get_session)",
        "fetch_repository_provider_token(\n        session, CredentialNamespace.REPOSITORY, provider_key\n    )",
        "get_github_rest_api_base_url(provider_key, metadata)",
        "httpx.AsyncClient()",
        "client.get(f\"{api_base_url}/user\", headers=headers)",
        "HTTPException(\n                status_code=user_resp.status_code, detail=\"Failed to fetch user info\"\n            )",
        "user_resp.json()",
        "user_data.get(\"email\")",
        "client.get(\n                f\"{api_base_url}/user/emails\", headers=headers\n            )",
        "emails_resp.json()",
        "next(\n                    (\n                        e[\"email\"]\n                        for e in emails\n                        if e.get(\"primary\") and e.get(\"verified\")\n                    ),\n                    None,\n                )",
        "e.get(\"primary\")",
        "e.get(\"verified\")",
        "user_data.get(\"name\")",
        "user_data.get(\"avatar_url\")"
      ],
      "nested_functions": [],
      "instance_variables": []
    }
  ],
  "classes": []
}