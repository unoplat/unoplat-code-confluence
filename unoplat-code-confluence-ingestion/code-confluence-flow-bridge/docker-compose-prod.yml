version: "3.5"

# Add default config
configs:
  temporal-dynamic-config:
    content: |
      system.forceSearchAttributesCacheRefreshOnRead:
        - value: true
          constraints: {}
      limit.maxIDLength:
        - value: 255
          constraints: {}

services:
  elasticsearch:
    container_name: temporal-elasticsearch
    environment:
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=512mb
      - cluster.routing.allocation.disk.watermark.high=256mb
      - cluster.routing.allocation.disk.watermark.flood_stage=128mb
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms256m -Xmx256m
      - xpack.security.enabled=false
    image: elasticsearch:7.17.27
    networks:
      - temporal-network
    expose:
      - 9200
    volumes:
      - /var/lib/elasticsearch/data
  postgresql:
    container_name: temporal-postgresql
    environment:
      POSTGRES_PASSWORD: temporal
      POSTGRES_USER: temporal
    image: postgres:13
    networks:
      - temporal-network
    expose:
      - 5432
    volumes:
      - /var/lib/postgresql/data
  temporal:
    container_name: temporal
    depends_on:
      - postgresql
      - elasticsearch
    environment:
      - DB=postgres12
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=postgresql
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - ENABLE_ES=true
      - ES_SEEDS=elasticsearch
      - ES_VERSION=v7
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    image: temporalio/auto-setup:1.26.2
    networks:
      - temporal-network
    ports:
      - 7233:7233
    configs:
      - source: temporal-dynamic-config
        target: /etc/temporal/config/dynamicconfig/development-sql.yaml
    healthcheck:
      test: ["CMD-SHELL", "tctl cluster health | grep -i SERVING || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
  temporal-admin-tools:
    container_name: temporal-admin-tools
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    image: temporalio/admin-tools:1.26.2
    networks:
      - temporal-network
    stdin_open: true
    tty: true
  temporal-ui:
    container_name: temporal-ui
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
      - TEMPORAL_CSRF_COOKIE_INSECURE=True
    image: temporalio/ui:2.34.0
    networks:
      - temporal-network
    ports:
      - 8080:8080
  neo4j:
    container_name: neo4j
    image: graphstack/dozerdb:5.25.1.0-alpha.1
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - ${HOME}/neo4j/data:/data
      - ${HOME}/neo4j/logs:/logs
      - ${HOME}/neo4j/import:/var/lib/neo4j/import
      - ${HOME}/neo4j/plugins:/plugins
    environment:
      NEO4J_AUTH: neo4j/password
      NEO4J_PLUGINS: '["apoc"]'
      NEO4J_apoc_export_file_enabled: "true"
      NEO4J_apoc_import_file_enabled: "true"
      NEO4J_dbms_security_procedures_unrestricted: "*"
    networks:
      - temporal-network
    healthcheck:
      test: ["CMD-SHELL", "neo4j status | grep -q 'Neo4j is running' || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 5
  code-confluence-flow-bridge:
    container_name: code-confluence-flow-bridge
    environment:
      - NEO4J_HOST=neo4j
      - NEO4J_PORT=7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=password
      - TEMPORAL_SERVER_ADDRESS=temporal:7233
    image: ghcr.io/unoplat/code-confluence-flow-bridge:0.8.0
    depends_on:
      temporal:
        condition: service_healthy
      neo4j:
        condition: service_healthy
    ports:
      - "8000:8000"
    networks:
      - temporal-network
    stdin_open: true
    tty: true

networks:
  temporal-network:
    driver: bridge
    name: temporal-network
# volumes:
#   temporal-shared-data:  # Define the shared volume
#     name: temporal-shared-data  # Optional: explicitly name the volume    
